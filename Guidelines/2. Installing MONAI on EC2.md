# How to install MONAI Label on an EC2 instance of AWS
## 1) Configuration of the created EC2 instance
To access the instance through the windows command window, we go through the file explorer to the folder where the security key of the instance we created previously is downloaded, and from the address bar of the file explorer we type 'cmd' and press ***Enter***, as shown below:

![cmd](https://github.com/doviedob/CardioAR3D/blob/main/Images/entrar%20cmd.png)

Subsequently, it will only be necessary to copy the command line specified in the SSH connection of the AWS console, and then copy it in the command window where it will ask us to authenticate to finally connect.

![conectarse_ssh](https://github.com/doviedob/CardioAR3D/blob/main/Images/conectar-ssh.png)
![cmd enlazado](https://github.com/doviedob/CardioAR3D/blob/main/Images/cmd_enlazado.png)

Finally, being inside the connected instance, it will be necessary to install the libraries that will be required for the correct operation of the server.

1. Verify the version of python installed
```
python3 --version 
```
2. Update drivers
```
sudo apt update
```
3. Get the file to install Anaconda3
```
wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh
```
***NOTE:*** To find the latest version of anaconda you can search in its [official repository](https://repo.anaconda.com/archive/)

4. Perform the bash to install the file
```
bash Anaconda3-2022.10-Linux-x86_64.sh
```
Initially, it will not recognize the anaconda commands, so it will be necessary to execute the following line of code:
```
source .bashrc
```
5. We will now be able to continue with the conda update:
```
conda update conda
```
## 2) Installation of CUDA and PyTorch drivers
At this point, the EC2 instance will have almost everything it needs to run MONAi Label, the next step is to install PyTorch and the necessary NVIDIA drivers to take advantage of the instance's GPU capabilities.

For the above, it will be necessary to check which version of PyTorch is compatible with the current CUDA driver. For this case, it was necessary to install CUDA version 12.1 which was compatible with the version of PyTorch that was available in its [official web site](https://pytorch.org/get-started/locally/) at the time.

With a simple Google search you will find the official NVIDIA website where you will find the different installation options, as in this case a Linux based instance is used, select the options according to your requirements:

![NVIDIA](https://github.com/doviedob/CardioAR3D/blob/main/Images/CUDA%20instalation.png)

In this way, the commands it gives for the installation are:
```
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
```
Subsequently, after performing the installation you will also need to install the CUDA toolkit which is obtained through the following command line:
```
sudo apt install nvidia-cuda-toolkit
```

Next, step 3 explains at what point it will be necessary to install the PyTorch libraries.

## 3) Creation of the MONAI Label environment

To do this it is necessary to have configured the EC2 instance from the previous guide. Again, from the console we will execute the following commands:

- We verify the version of conda installed in the instance:
```
conda --version
```
- We will create the virtual environment where MONAI Label will run:
```
conda create -n monailabel-env python=3.9
```
- We will run the environment:
```
conda activate monailabel-env
```
- We will install the 'gcc' driver that we will need for the following steps:
```
sudo apt-get install gcc
```
- This is where the PyTorch drivers described in step 2 obtained from its official website will be installed. Check the [official website](https://pytorch.org/get-started/locally/):
```
pip3 install torch torchvision torchaudio
```
***NOTE:*** To verify that the CUDA and Pytorch drivers are correctly installed we can run the following command line:
```
python -c "import torch; print(torch.__version__)"
```
And additionally we can verify that PyTorch is using the GPU with the following instructions:
1. Open the Ubuntu terminal.
2. Open the Python interpreter by typing python in the terminal.
3. Import PyTorch by typing *'import torch'*.
4. Check if a GPU is available by executing the following code:
```
if torch.cuda.is_available():
    print("PyTorch está utilizando la GPU:")
    print(torch.cuda.get_device_name(0))
else:
    print("PyTorch no está utilizando la GPU.")
```
This will print "PyTorch is using GPU:" and the GPU name. Otherwise, it will print "PyTorch is not using GPU:". To exit this check we will press the CTRL+D combination.

- We install MONAI Label
```
pip install monailabel
```
- We verify that it is installed with the following command:
```
pip freeze
```
- We review what is available when installing MONAI:
```
monailabel -h
```
- We downloaded the radiology app:
```
monailabel apps --download --name radiology --output apps
```
- We reviewed the datasets available for testing MONAI:
```
monailabel datasets
```
- With the following command we save one of the available datasets by simply adding the name in the underlined part:
```
monailabel datasets --download --name Task02_Heart --output datasets
```
- To correctly execute the 'wheel' command it is necessary to install the Dicom web server (In some cases this is optional):
```
pip install dicomweb-client[gcp]
```
- Finally, we will start the server where MONAI is located:
```
monailabel start_server --app apps/radiology --studies datasets/Task02_Heart/imagesTr --conf models segmentation
```

With the above instructions, we can verify if the MONAI Label server is running correctly by searching in the browser for the public IP address of the instance followed by the incoming port. The following will be observed:

![servidor funcionando](https://github.com/doviedob/CardioAR3D/blob/main/Images/servidor%20running.png)
